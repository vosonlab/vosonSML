% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Collect.twitter.R
\name{Collect.twitter}
\alias{Collect.twitter}
\title{Collect data from twitter for generating different types of networks}
\usage{
\method{Collect}{twitter}(credential, searchTerm = "",
  searchType = "recent", numTweets = 100, includeRetweets = TRUE,
  retryOnRateLimit = FALSE, writeToFile = FALSE, verbose = FALSE,
  ...)
}
\arguments{
\item{credential}{A \code{credential} object generated from \code{Authenticate} with class name \code{"twitter"}.}

\item{searchTerm}{Character string. Specifies a search term or phrase (e.g. "Australian politics") or hashtag (e.g. 
"#auspol"). Many query operators are available - see the Twitter documentation for more information: 
https://dev.twitter.com/rest/public/search}

\item{searchType}{Character string. Returns filtered tweets as per search type \code{recent}, \code{mixed} or 
\code{popular}. Default type is \code{recent}.}

\item{numTweets}{Numeric. Specifies how many tweets to be collected. Defaults is \code{100}.}

\item{includeRetweets}{Logical. Specifies if the search should filter out retweets. Defaults is \code{TRUE}.}

\item{retryOnRateLimit}{Logical. Default is \code{FALSE}.}

\item{writeToFile}{Logical. Write collected data to file. Default is \code{FALSE}.}

\item{verbose}{Logical. Output additional information about the data collection. Default is \code{FALSE}.}

\item{...}{Arguments passed on to \code{rtweet::search_tweets}
\describe{
  \item{geocode}{Geographical limiter of the template
"latitude,longitude,radius" e.g., \code{geocode =
"37.78,-122.40,1mi"}.}
  \item{max_id}{Character, returns results with an ID less
than (that is, older than) or equal to `max_id`.  Especially
useful for large data returns that require multiple iterations
interrupted by user time constraints. For searches exceeding
18,000 tweets, users are encouraged to take advantage of rtweet's
internal automation procedures for waiting on rate limits by
setting \code{retryonratelimit} argument to TRUE.  It some cases,
it is possible that due to processing time and rate limits,
retrieving several million tweets can take several hours or even
multiple days. In these cases, it would likely be useful to
leverage \code{retryonratelimit} for sets of tweets and
\code{max_id} to allow results to continue where previous efforts
left off.}
  \item{parse}{Logical, indicating whether to return parsed
data.frame, if true, or nested list, if false. By default,
\code{parse = TRUE} saves users from the wreck of time and
frustration associated with disentangling the nasty nested list
returned from Twitter's API. As Twitter's APIs are subject to
change, this argument would be especially useful when changes to
Twitter's APIs affect performance of internal parsers. Setting
\code{parse = FALSE} also ensures the maximum amount of possible
information is returned. By default, the rtweet parse process
returns nearly all bits of information returned from
Twitter. However, users may occasionally encounter new or
omitted variables. In these rare cases, the nested list object
will be the only way to access these variables.}
}}
}
\value{
A data.frame object with class names \code{"datasource"} and \code{"twitter"}.
}
\description{
This function collects data from twitter based on hashtags or search terms, and structures the data into a data 
frame of class \code{dataSource, twitter}, ready for creating networks for further analysis. Relationships are then 
mapped for entities of interest in the data (e.g. users, terms, hashtags) and structured into a data frame format 
suitable for creating unimodal networks (\code{CreateActorNetwork}), bimodal networks (\code{CreateBimodalNetwork}), 
and semantic networks (\code{CreateSemanticNetwork}).

The maximum number of tweets for a single call of \code{CollectDataTwitter} is 18000 as per the twitter standard
API rate limits. The standard API only returns tweets for the last 6 to 9 days.

Language support is available, using the \code{language} parameter. The user can restrict tweets returned to a 
particular language, using the ISO 639-1 code. For example, restricting to English would use \code{language="en"}. 
The full list of codes is available here: https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes.

A variety of query operators are available through the twitter API. For example, "love OR hate" returns any tweets 
containing either term (or both). For more information see the twitter API documentation (under the heading
'Query Operators'): https://dev.twitter.com/rest/public/search
}
\examples{
\dontrun{
# search and collect 100 recent tweets for the hashtag #auspol
myTwitterData <- twitterAuth \%>\% 
  Collect(searchTerm = "#auspol", searchType = "recent", numTweets = 100, verbose = TRUE, 
          includeRetweets = FALSE, retryOnRateLimit = TRUE, writeToFile = TRUE)
}

}
