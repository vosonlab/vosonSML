% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Collect.web.R
\name{Collect.web}
\alias{Collect.web}
\title{Collect hyperlinks from web pages}
\usage{
\method{Collect}{web}(
  credential,
  pages,
  waitTime = c(3, 10),
  ua = getOption("HTTPUserAgent"),
  writeToFile = FALSE,
  verbose = TRUE,
  ...
)
}
\arguments{
\item{credential}{A \code{credential} object generated from \code{Authenticate} with class name \code{"reddit"}.}

\item{pages}{List. List of web pages to crawl.}

\item{waitTime}{Numeric vector. Time range in seconds to select random wait from in-between url collection requests.
Minimum is 3 seconds. Default is \code{c(3, 10)} for a wait time chosen from between 3 and 10 seconds.}

\item{ua}{Character string. Override User-Agent string to use in web page requests. Default is
\code{option("HTTPUserAgent")} value as set by vosonSML.}

\item{writeToFile}{Logical. Write collected data to file. Default is \code{FALSE}.}

\item{verbose}{Logical. Output additional information about the data collection. Default is \code{TRUE}.}

\item{...}{Additional parameters passed to function. Not used in this method.}
}
\value{
A \code{data.frame} object with class names \code{"datasource"} and \code{"reddit"}.
}
\description{
Collects hyperlinks from web pages and structures the data into a dataframe with the
class names \code{"datasource"} and \code{"web"}.
}
\examples{
\dontrun{
webData <- webAuth \%>\%
  Collect(pages = list(), writeToFile = TRUE)
}

}
